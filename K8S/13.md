# Lab13 -  StatefulSet

## Commands outputs

```bash
$ kubectl get po,sts,svc,pvc
NAME                          READY   STATUS    RESTARTS       AGE
pod/helm-app-0                1/1     Running   0              100s
pod/helm-app-1                1/1     Running   0              90s

NAME                        READY   AGE
statefulset.apps/helm-app   2/2     100s
NAME                   TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
service/kubernetes     ClusterIP      10.96.0.1      <none>        443/TCP        25d
service/helm-app       LoadBalancer   10.111.22.69   <pending>     80:32642/TCP   100s

NAME                                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/persistent-volume-helm-app-0   Bound    pvc-e210a37c-651e-4487-a283-ce934fdca947   64Mi       RWO            standard       100s
persistentvolumeclaim/persistent-volume-helm-app-1   Bound    pvc-9e3d7dc1-e5cb-4014-87c5-4b43b1074459   64Mi       RWO            standard       90s
```

## Replicas

```bash
$ kubectl exec pod/helm-app-0 -- tail -c 140 persistent/visits.json
 "Moscow time: 17:25:23", "Moscow time: 17:25:33", "Moscow time: 17:25:33", "Moscow time: 17:25:43", "Moscow time: 17:25:43"], "total": 11}
$ kubectl exec pod/helm-app-1 -- tail -c 140 persistent/visits.json
 "Moscow time: 17:26:03", "Moscow time: 17:26:13", "Moscow time: 17:26:13", "Moscow time: 17:26:23", "Moscow time: 17:26:23"], "total": 18}
```

We have different timestamps for each replica, and this occures due to:

- the volum is different for each replica StatefulSet
- They don't share the same amount of requests distrebuted by the Load Balancer

## Ordering

In our app, the replicas are independent from each other, each one can work separetly even if the other one fail or stop, so ordering is unnecessary
How to make them work in parallel? Added parameter `podManagementPolicy: "Parallel"` to `statefulset.yaml`
